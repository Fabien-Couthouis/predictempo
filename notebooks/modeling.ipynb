{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import sklearn.model_selection as skm\n",
    "from joblib import parallel_backend\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    make_scorer,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_POSTE   : numéro Météo-France du poste sur 8 chiffres\n",
    "# NOM_USUEL   : nom usuel du poste\n",
    "# LAT         : latitude, négative au sud (en degrés et millionièmes de degré)\n",
    "# LON         : longitude, négative à l’ouest de GREENWICH (en degrés et millionièmes de degré)\n",
    "# ALTI        : altitude du pied de l'abri ou du pluviomètre si pas d'abri (en m)\n",
    "# AAAAMMJJ    : date de la mesure (année mois jour)\n",
    "# RR          : quantité de précipitation tombée en 24 heures (de 06h FU le jour J à 06h FU le jour J+1). La valeur relevée à J+1 est affectée au jour J (en mm et 1/10)\n",
    "# TN          : température minimale sous abri (en °C et 1/10)\n",
    "# HTN         : heure de TN (hhmm)\n",
    "# TX          : température maximale sous abri (en °C et 1/10)\n",
    "# HTX         : heure de TX (hhmm)\n",
    "# TM          : moyenne quotidienne des températures horaires sous abri (en °C et 1/10)\n",
    "# TNTXM       : moyenne quotidienne (TN+TX)/2 (en °C et 1/10)\n",
    "# TAMPLI      : amplitude thermique quotidienne : écart entre TX et TN quotidiens (TX-TN) (en °C et 1/10)\n",
    "# TNSOL       : température quotidienne minimale à 10 cm au-dessus du sol (en °C et 1/10)\n",
    "# TN50        : température quotidienne minimale à 50 cm au-dessus du sol (en °C et 1/10)\n",
    "# DG          : durée de gel sous abri (T ≤ 0°C) (en mn)\n",
    "# FFM         : moyenne quotidienne de la force du vent moyenné sur 10 mn, à 10 m (en m/s et 1/10)\n",
    "# FF2M        : moyenne quotidienne de la force du vent moyenné sur 10 mn, à 2 m (en m/s et 1/10)\n",
    "# FXY         : maximum quotidien de la force maximale horaire du vent moyenné sur 10 mn, à 10 m (en m/s et 1/10)\n",
    "# DXY         : direction de FXY (en rose de 360)\n",
    "# HXY         : heure de FXY (hhmm)\n",
    "# FXI         : maximum quotidien de la force maximale horaire du vent instantané, à 10 m (en m/s et 1/10)\n",
    "# DXI         : direction de FXI (en rose de 360)\n",
    "# HXI         : heure de FXI (hhmm)\n",
    "# FXI2        : maximum quotidien de la force maximale horaire du vent instantané, à 2 m (en m/s et 1/10)\n",
    "# DXI2        : direction de FXI2 (en rose de 360)\n",
    "# HXI2        : heure de FXI2 (hhmm)\n",
    "# FXI3S       : maximum quotidien de la force maximale horaire du vent moyenné sur 3 s, à 10 m (en m/s et 1/10)\n",
    "# DXI3S       : direction de FXI3S (en rose de 360)\n",
    "# HXI3S       : heure de FXI3S (hhmm)\n",
    "# DRR         : durée des précipitations (en mn)\n",
    "\n",
    "# A chaque donnée est associé un code qualité (ex: T;QT) :\n",
    "#  9 : donnée filtrée (la donnée a passé les filtres/contrôles de premiers niveaux)\n",
    "#  0 : donnée protégée (la donnée a été validée définitivement par le climatologue)\n",
    "#  1 : donnée validée (la donnée a été validée par contrôle automatique ou par le climatologue)\n",
    "#  2 : donnée douteuse en cours de vérification (la donnée a été mise en doute par contrôle automatique)\n",
    "\n",
    "# D'une façon générale, les valeurs fournies sont données avec une précision qui correspond globalement à la résolution de l'appareil de mesure de la valeur.\n",
    "# Toutefois, il peut arriver, pour des raisons techniques de stokage ou d'extraction des valeurs, que cette règle ne soit pas respectée.\n",
    "# Du fait d'arrondis, il peut ponctuellement arriver que des valeurs de base à un pas de temps inférieur (par exemple données minutes) ne soient pas exactement cohérentes avec leurs correspondants sur un pas de temps supérieur (par exemple données horaires)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\predictempo\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.10-windows-x86_64-none\\Lib\\importlib\\__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/merged_meteo_red_days_from_20170101.feather\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.columns)\n\u001b[32m      3\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\predictempo\\.venv\\Lib\\site-packages\\pandas\\io\\feather_format.py:111\u001b[39m, in \u001b[36mread_feather\u001b[39m\u001b[34m(path, columns, use_threads, storage_options, dtype_backend)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_feather\u001b[39m(\n\u001b[32m     70\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m     dtype_backend: DtypeBackend | lib.NoDefault = lib.no_default,\n\u001b[32m     75\u001b[39m ) -> DataFrame:\n\u001b[32m     76\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m    Load a feather-format object from the file path.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    109\u001b[39m \u001b[33;03m    >>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feather\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\predictempo\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "df = pd.read_feather(\"../data/merged_meteo_red_days_from_20170101.feather\")\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAMMJJ</th>\n",
       "      <th>TN_BORDEAUX</th>\n",
       "      <th>TN_LILLE</th>\n",
       "      <th>TN_LYON</th>\n",
       "      <th>TN_MARSEILLE</th>\n",
       "      <th>TN_MONTPELLIER</th>\n",
       "      <th>TN_NANTES</th>\n",
       "      <th>TN_NICE</th>\n",
       "      <th>TN_PARIS</th>\n",
       "      <th>TN_REIMS</th>\n",
       "      <th>...</th>\n",
       "      <th>TAMPLI_MONTPELLIER</th>\n",
       "      <th>TAMPLI_NANTES</th>\n",
       "      <th>TAMPLI_NICE</th>\n",
       "      <th>TAMPLI_PARIS</th>\n",
       "      <th>TAMPLI_REIMS</th>\n",
       "      <th>TAMPLI_RENNES</th>\n",
       "      <th>TAMPLI_STRASBOURG</th>\n",
       "      <th>TAMPLI_TOULON</th>\n",
       "      <th>TAMPLI_TOULOUSE</th>\n",
       "      <th>is_red_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>20240307</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>20240308</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>20240309</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>20240310</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>11.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>20240311</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>13.7</td>\n",
       "      <td>13.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AAAAMMJJ  TN_BORDEAUX  TN_LILLE  TN_LYON  TN_MARSEILLE  TN_MONTPELLIER  \\\n",
       "2622  20240307          5.7       3.4      0.3           0.8             0.5   \n",
       "2623  20240308          8.9       2.4      4.8           7.0             8.7   \n",
       "2624  20240309          7.5       5.2      5.9           7.7             9.9   \n",
       "2625  20240310          3.3       7.6      5.7           9.2             6.3   \n",
       "2626  20240311          4.5       7.6      5.1           6.7             7.6   \n",
       "\n",
       "      TN_NANTES  TN_NICE  TN_PARIS  TN_REIMS  ...  TAMPLI_MONTPELLIER  \\\n",
       "2622        4.0      7.4       3.8      -0.6  ...                12.5   \n",
       "2623        6.9      6.9       3.6      -1.0  ...                 4.5   \n",
       "2624        6.2      8.2       6.4       2.0  ...                 3.5   \n",
       "2625        0.9      8.4       7.1       5.5  ...                 8.8   \n",
       "2626        3.9      8.1       6.4       0.2  ...                 7.6   \n",
       "\n",
       "      TAMPLI_NANTES  TAMPLI_NICE  TAMPLI_PARIS  TAMPLI_REIMS  TAMPLI_RENNES  \\\n",
       "2622           10.2          7.2          10.4          13.7           11.0   \n",
       "2623            5.2          6.4          10.3          15.2            6.5   \n",
       "2624            3.7          4.7           8.1          12.7            4.5   \n",
       "2625           11.9          4.9           4.3           5.5           13.1   \n",
       "2626           10.1          5.4           6.6          13.7           13.9   \n",
       "\n",
       "      TAMPLI_STRASBOURG  TAMPLI_TOULON  TAMPLI_TOULOUSE  is_red_day  \n",
       "2622                5.5           13.4             10.7        True  \n",
       "2623               12.3            5.5              5.6       False  \n",
       "2624               12.3            4.4              6.3       False  \n",
       "2625                5.3            5.0             12.9       False  \n",
       "2626               10.5            8.4              4.3        True  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove days after 20240311\n",
    "df = df[df[\"AAAAMMJJ\"] < 20240401]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAMMJJ                0\n",
      "TN_BORDEAUX             0\n",
      "TN_LILLE                0\n",
      "TN_LYON                 0\n",
      "TN_MARSEILLE            0\n",
      "TN_MONTPELLIER        365\n",
      "TN_NANTES               0\n",
      "TN_NICE                 0\n",
      "TN_PARIS                0\n",
      "TN_REIMS                0\n",
      "TN_RENNES               0\n",
      "TN_STRASBOURG           0\n",
      "TN_TOULON               0\n",
      "TN_TOULOUSE             0\n",
      "TX_BORDEAUX             0\n",
      "TX_LILLE                0\n",
      "TX_LYON                 0\n",
      "TX_MARSEILLE            0\n",
      "TX_MONTPELLIER        365\n",
      "TX_NANTES               0\n",
      "TX_NICE                 0\n",
      "TX_PARIS                0\n",
      "TX_REIMS                0\n",
      "TX_RENNES               0\n",
      "TX_STRASBOURG           0\n",
      "TX_TOULON               0\n",
      "TX_TOULOUSE             0\n",
      "TNTXM_BORDEAUX          0\n",
      "TNTXM_LILLE             0\n",
      "TNTXM_LYON              0\n",
      "TNTXM_MARSEILLE         0\n",
      "TNTXM_MONTPELLIER     365\n",
      "TNTXM_NANTES            0\n",
      "TNTXM_NICE              0\n",
      "TNTXM_PARIS             0\n",
      "TNTXM_REIMS             0\n",
      "TNTXM_RENNES            0\n",
      "TNTXM_STRASBOURG        0\n",
      "TNTXM_TOULON            0\n",
      "TNTXM_TOULOUSE          0\n",
      "TAMPLI_BORDEAUX         0\n",
      "TAMPLI_LILLE            0\n",
      "TAMPLI_LYON             0\n",
      "TAMPLI_MARSEILLE        0\n",
      "TAMPLI_MONTPELLIER    365\n",
      "TAMPLI_NANTES           0\n",
      "TAMPLI_NICE             0\n",
      "TAMPLI_PARIS            0\n",
      "TAMPLI_REIMS            0\n",
      "TAMPLI_RENNES           0\n",
      "TAMPLI_STRASBOURG       0\n",
      "TAMPLI_TOULON           0\n",
      "TAMPLI_TOULOUSE         0\n",
      "is_red_day              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['TN_MONTPELLIER', 'TX_MONTPELLIER', 'TNTXM_MONTPELLIER',\n",
       "       'TAMPLI_MONTPELLIER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nan values and show nan cols:\n",
    "\n",
    "print(df.isna().sum())\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df.columns[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop montepellier etc\n",
    "cities_to_drop = [\"MONTPELLIER\", \"REIMS\", \"RENNES\", \"NICE\"]\n",
    "\n",
    "\n",
    "df.drop(\n",
    "    columns=[c for c in df.columns if c.split(\"_\")[-1] in cities_to_drop],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "assert df.isna().sum().sum() == 0, \"There are still NaN values in the dataframe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a is week day feature:\n",
    "daydt = pd.to_datetime(df[\"AAAAMMJJ\"], format=\"%Y%m%d\").dt\n",
    "df[\"is_week_day\"] = (daydt.dayofweek < 5).astype('category')\n",
    "\n",
    "\n",
    "# Feature as int\n",
    "df[\"is_red_day\"] = df[\"is_red_day\"].astype(int)\n",
    "\n",
    "# if last day was red feature\n",
    "df[\"last_day_was_red\"] = df[\"is_red_day\"].shift(1).fillna(0).astype('category')\n",
    "\n",
    "# Red days in last week feature\n",
    "df[\"red_days_last_week\"] = (\n",
    "    df[\"is_red_day\"]\n",
    "    .rolling(window=7, min_periods=1)\n",
    "    .sum()\n",
    "    .shift(1)\n",
    "    .fillna(0)\n",
    "    .astype(bool)\n",
    ")\n",
    "df.drop(columns=[\"last_day_was_red\"], inplace=True)\n",
    "\n",
    "# Month feature\n",
    "df[\"month\"] = daydt.month.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fab47\\AppData\\Local\\Temp\\ipykernel_10372\\438820387.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[~((daydt.year == 2017) & (daydt.month < 4))]\n"
     ]
    }
   ],
   "source": [
    "# Remove data between  01/04 and 01/11 and prior to 2017-04\n",
    "df = df[~((daydt.month >= 4) & (daydt.month <= 10))]\n",
    "df = df[~((daydt.year == 2017) & (daydt.month < 4))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_red_day\n",
       "0    892\n",
       "1    147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  show values count in y\n",
    "df[\"is_red_day\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_table(\n",
    "    y_true: np.ndarray | list, y_pred: np.ndarray | list\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Rows: Actual, Columns: Predicted. Aligns inputs by position (not index).\"\"\"\n",
    "    y_true_series = pd.Series(np.asarray(y_true), name=\"Actual\")\n",
    "    y_pred_series = pd.Series(np.asarray(y_pred), name=\"Predicted\")\n",
    "\n",
    "    if len(y_true_series) != len(y_pred_series):\n",
    "        raise ValueError(\n",
    "            f\"y_true and y_pred must have same length, got {len(y_true_series)} and {len(y_pred_series)}\"\n",
    "        )\n",
    "\n",
    "    ct = pd.crosstab(y_true_series, y_pred_series)\n",
    "    return ct\n",
    "\n",
    "\n",
    "def evaluate(model, X, y, plot_roc_rurve=False, threshold=0.5):\n",
    "    y_probs = model.predict_proba(X)[:, 1]\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y, y_pred)}\")\n",
    "    print(\"Precision\", precision_score(y, y_pred))\n",
    "    print(\"Recall\", recall_score(y, y_pred))\n",
    "    print(\"F1 score\", f1_score(y, y_pred))\n",
    "    print(\"F2 score\", fbeta_score(y, y_pred, beta=2))\n",
    "    print(\"Average precision (AUPRC)\", average_precision_score(y, y_probs))\n",
    "\n",
    "    display(confusion_table(y, y_pred))\n",
    "\n",
    "    if plot_roc_rurve:\n",
    "        y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fig = px.area(\n",
    "            x=fpr,\n",
    "            y=tpr,\n",
    "            title=f\"ROC Curve (AUC={roc_auc:.4f})\",\n",
    "            labels=dict(x=\"False Positive Rate\", y=\"True Positive Rate\"),\n",
    "            width=700,\n",
    "            height=500,\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"is_red_day\", \"AAAAMMJJ\"], axis=1)\n",
    "todrop = []\n",
    "for c in X.columns:\n",
    "    if \"TAMPLI\" in c or \"RR\" in c or \"FFM\" in c or \"TM\" in c or \"TNTXM\" in c:\n",
    "        todrop.append(c)\n",
    "\n",
    "\n",
    "X = X.drop(todrop, axis=1)\n",
    "y = df[\"is_red_day\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = skm.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TN_BORDEAUX', 'TN_LILLE', 'TN_LYON', 'TN_MARSEILLE', 'TN_NANTES',\n",
       "       'TN_PARIS', 'TN_STRASBOURG', 'TN_TOULON', 'TN_TOULOUSE', 'TX_BORDEAUX',\n",
       "       'TX_LILLE', 'TX_LYON', 'TX_MARSEILLE', 'TX_NANTES', 'TX_PARIS',\n",
       "       'TX_STRASBOURG', 'TX_TOULON', 'TX_TOULOUSE', 'is_week_day',\n",
       "       'red_days_last_week', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters found:  {'scale_pos_weight': 5, 'reg_lambda': 1, 'reg_alpha': 10, 'num_leaves': 15, 'n_estimators': 100, 'min_child_samples': 50, 'max_depth': 3, 'learning_rate': 0.05}\n",
      "Best score: 0.6381369748676083\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "RUN_HP_TUNING = True\n",
    "\n",
    "if RUN_HP_TUNING:\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"learning_rate\": [0.01, 0.05],\n",
    "        \"max_depth\": [3, 5, 10],\n",
    "        \"num_leaves\": [15, 31],\n",
    "        \"min_child_samples\": [20, 50, 100],\n",
    "        \"reg_alpha\": [0.1, 1, 10],\n",
    "        \"reg_lambda\": [0.1, 1, 10],\n",
    "        \"scale_pos_weight\": [5, 10, 20],\n",
    "    }\n",
    "\n",
    "    # Perform GridSearchCV\n",
    "    lgbm = LGBMClassifier(random_state=SEED, force_row_wise=True, verbose=-1, n_jobs=-1)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        lgbm,\n",
    "        param_grid,\n",
    "        scoring=\"average_precision\",  # This is the PR AUC alias,\n",
    "        n_iter=50,\n",
    "        cv=kf,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "\n",
    "    with parallel_backend(\"loky\"):\n",
    "        random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and evaluate\n",
    "    print(\"Best parameters found: \", random_search.best_params_)\n",
    "    print(\"Best score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Average Precision scores: [0.64681238 0.68184614 0.58328588 0.64252494 0.66743472]\n",
      "Mean CV Average Precision: 0.6443808122003875\n"
     ]
    }
   ],
   "source": [
    "# Obtained with random search\n",
    "best_params =  {\n",
    "    \"scale_pos_weight\": 5,\n",
    "    \"reg_lambda\": 1,\n",
    "    \"reg_alpha\": 10,\n",
    "    \"num_leaves\": 15,\n",
    "    \"n_estimators\": 100,\n",
    "    \"min_child_samples\": 50,\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.05,\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=0, force_row_wise=True, verbose=-1, **best_params)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# We use cv to ensure data efficiency\n",
    "calibrated_lgbm = CalibratedClassifierCV(\n",
    "    estimator=lgbm,\n",
    "    method=\"sigmoid\",  # Platt scaling\n",
    "    cv=kf,\n",
    "    ensemble=False, # for easier onnx export\n",
    ")\n",
    "calibrated_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# print cv average_precision scores\n",
    "cv_scores = cross_val_score(\n",
    "    calibrated_lgbm,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=kf,\n",
    ")\n",
    "print(\"CV Average Precision scores:\", cv_scores)\n",
    "print(\"Mean CV Average Precision:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Out-of-Fold probabilities...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calibrated_lgbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m     fig.show()\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating Out-of-Fold probabilities...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m plot_cv_pr_curve(\u001b[43mcalibrated_lgbm\u001b[49m, X_train, y_train, kf)\n",
      "\u001b[31mNameError\u001b[39m: name 'calibrated_lgbm' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_cv_pr_curve(calibrated_lgbm, X_train, y_train, kf):\n",
    "    \"\"\"Plot Cross-Validated Precision-Recall Curve using OOF probabilities\"\"\"\n",
    "    y_oof_probs = cross_val_predict(\n",
    "        calibrated_lgbm, X_train, y_train, cv=kf, method=\"predict_proba\"\n",
    "    )[:, 1]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_oof_probs)\n",
    "    pr_auc = average_precision_score(y_train, y_oof_probs)\n",
    "\n",
    "    # We add a 1 to the end of thresholds to match the length of precision/recall\n",
    "    thresholds_padded = np.append(thresholds, 1)\n",
    "    pr_curve_df = pd.DataFrame(\n",
    "        {\"Recall\": recall, \"Precision\": precision, \"Threshold\": thresholds_padded}\n",
    "    )\n",
    "\n",
    "    fig = px.area(\n",
    "        pr_curve_df,\n",
    "        x=\"Recall\",\n",
    "        y=\"Precision\",\n",
    "        title=f\"Cross-Validated Precision-Recall Curve (PR-AUC = {pr_auc:.4f})\",\n",
    "        hover_data=[\"Threshold\"],\n",
    "        labels=dict(\n",
    "            x=\"Recall (Ability to catch positives)\",\n",
    "            y=\"Precision (Accuracy of positive calls)\",\n",
    "        ),\n",
    "        width=700,\n",
    "        height=500,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "print(\"Generating Out-of-Fold probabilities...\")\n",
    "plot_cv_pr_curve(calibrated_lgbm, X_train, y_train, kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m THRESHOLD = \u001b[32m0.25\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mevaluate\u001b[49m(calibrated_lgbm, X_train, y_train, threshold=THRESHOLD)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTest set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m evaluate(calibrated_lgbm, X_test, y_test, threshold=THRESHOLD)\n",
      "\u001b[31mNameError\u001b[39m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.25\n",
    "\n",
    "print(\"Train set\")\n",
    "evaluate(calibrated_lgbm, X_train, y_train, threshold=THRESHOLD)\n",
    "\n",
    "print(\"Test set\")\n",
    "evaluate(calibrated_lgbm, X_test, y_test, threshold=THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore incorrect preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 incorrect predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAAMMJJ</th>\n",
       "      <th>TN_BORDEAUX</th>\n",
       "      <th>TN_LILLE</th>\n",
       "      <th>TN_LYON</th>\n",
       "      <th>TN_MARSEILLE</th>\n",
       "      <th>TN_NANTES</th>\n",
       "      <th>TN_PARIS</th>\n",
       "      <th>TN_STRASBOURG</th>\n",
       "      <th>TN_TOULON</th>\n",
       "      <th>TN_TOULOUSE</th>\n",
       "      <th>...</th>\n",
       "      <th>TAMPLI_PARIS</th>\n",
       "      <th>TAMPLI_STRASBOURG</th>\n",
       "      <th>TAMPLI_TOULON</th>\n",
       "      <th>TAMPLI_TOULOUSE</th>\n",
       "      <th>is_red_day</th>\n",
       "      <th>is_week_day</th>\n",
       "      <th>red_days_last_week</th>\n",
       "      <th>month</th>\n",
       "      <th>y_pred_proba</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>20230308</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>10.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.112434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>20190319</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>12.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.113075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>20220128</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>13.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>20220120</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>20190205</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.633103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>20180222</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.624221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>20180320</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.454363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>20171201</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>0.695886</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>20220124</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>20210209</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.301487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AAAAMMJJ  TN_BORDEAUX  TN_LILLE  TN_LYON  TN_MARSEILLE  TN_NANTES  \\\n",
       "2257  20230308          7.9       0.8      1.9           4.7        7.6   \n",
       "807   20190319          5.8       0.0      1.6           3.4        3.5   \n",
       "1853  20220128         -0.9       0.2     -2.7          -1.4        2.1   \n",
       "1845  20220120          5.2       1.4      0.7           1.7        2.9   \n",
       "765   20190205          3.6       2.1     -2.1           1.9        3.7   \n",
       "417   20180222         -0.5      -2.4     -0.3          -0.5       -2.1   \n",
       "443   20180320          1.3      -2.1      0.6           2.0       -0.2   \n",
       "334   20171201          0.3      -0.7      0.0          -0.4       -0.5   \n",
       "1849  20220124         -1.3       0.2     -2.8           0.7        0.5   \n",
       "1500  20210209          5.2      -6.5      1.5           5.6       -1.1   \n",
       "\n",
       "      TN_PARIS  TN_STRASBOURG  TN_TOULON  TN_TOULOUSE  ...  TAMPLI_PARIS  \\\n",
       "2257       5.3            2.9        6.4          3.6  ...           9.8   \n",
       "807        4.1           -0.3        3.4          5.7  ...           9.5   \n",
       "1853       6.3            0.2        1.0         -2.6  ...           1.2   \n",
       "1845       3.8            1.3        4.0          3.9  ...           3.3   \n",
       "765        3.1           -3.3        2.8          3.8  ...           5.7   \n",
       "417       -1.2           -2.1        3.6          0.6  ...           6.2   \n",
       "443       -1.3           -2.8        6.7          2.4  ...          10.1   \n",
       "334        0.8            0.1        3.7          1.9  ...           3.7   \n",
       "1849       0.7           -2.0        1.1          2.1  ...           6.9   \n",
       "1500      -2.9           -3.5        7.4          6.2  ...           2.3   \n",
       "\n",
       "      TAMPLI_STRASBOURG  TAMPLI_TOULON  TAMPLI_TOULOUSE  is_red_day  \\\n",
       "2257               12.7           10.8             17.5           1   \n",
       "807                12.1           11.7              5.7           1   \n",
       "1853                5.8           13.6              5.5           0   \n",
       "1845                4.2           10.3              2.9           0   \n",
       "765                11.5           11.7              7.9           0   \n",
       "417                 5.8            7.8              4.6           0   \n",
       "443                 7.4            8.8              2.4           0   \n",
       "334                 2.5            5.2              2.8           0   \n",
       "1849                9.6           12.5             10.9           0   \n",
       "1500                1.8            7.3              7.1           0   \n",
       "\n",
       "      is_week_day  red_days_last_week  month  y_pred_proba  y_pred  \n",
       "2257         True                True      3      0.112434       0  \n",
       "807          True               False      3      0.113075       0  \n",
       "1853         True                True      1      0.508723       1  \n",
       "1845         True                True      1      0.563467       1  \n",
       "765          True                True      2      0.633103       1  \n",
       "417          True               False      2      0.624221       1  \n",
       "443          True               False      3      0.454363       1  \n",
       "334          True                True     12      0.695886       1  \n",
       "1849         True                True      1      0.706879       1  \n",
       "1500         True               False      2      0.301487       1  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore incorrect predictions\n",
    "y_pred_proba = calibrated_lgbm.predict_proba(X_test)[:, 1]\n",
    "X_test_indices = X_test.index\n",
    "df_test = df.loc[X_test_indices].copy()\n",
    "df_test[\"y_pred_proba\"] = y_pred_proba\n",
    "df_test[\"y_pred\"] = (y_pred_proba >= THRESHOLD).astype(int)\n",
    "\n",
    "incorrect_preds = df_test[df_test[\"is_red_day\"] != df_test[\"y_pred\"]]\n",
    "print(len(incorrect_preds), \"incorrect predictions\")\n",
    "assert all(\n",
    "    incorrect_preds[\"y_pred\"] != incorrect_preds[\"is_red_day\"]\n",
    "), \"y_pred should be different from is_red_day\"\n",
    "incorrect_preds.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "No classes found. Need to call fit beforehand.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m initial_types = [(\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, FloatTensorType([\u001b[38;5;28;01mNone\u001b[39;00m, X_train_np.shape[\u001b[32m1\u001b[39m]]))]\n\u001b[32m     10\u001b[39m input_names_str = \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(X_train.columns)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m onnx_model = \u001b[43mconvert_lightgbm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlgbm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoc_string\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPredict if the next day will be a red day.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mInput names: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minput_names_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Simplify the ONNX model to avoid unsupported operators in app later on\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# simp_model, check = simplify(onnx_model)\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# assert check, \"Simplified ONNX model could not be validated\"\u001b[39;00m\n\u001b[32m     23\u001b[39m simp_model, check = onnx_model, \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fab47\\Documents\\dev\\predictempo\\.venv\\Lib\\site-packages\\onnxmltools\\convert\\main.py:228\u001b[39m, in \u001b[36mconvert_lightgbm\u001b[39m\u001b[34m(model, name, initial_types, doc_string, target_opset, targeted_onnx, custom_conversion_functions, custom_shape_calculators, without_onnx_ml, zipmap, split)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    223\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlightgbm is not installed. Please install lightgbm to use this feature.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m     )\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlightgbm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconvert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoc_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtargeted_onnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_conversion_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_shape_calculators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwithout_onnx_ml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fab47\\Documents\\dev\\predictempo\\.venv\\Lib\\site-packages\\onnxmltools\\convert\\lightgbm\\convert.py:87\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(model, name, initial_types, doc_string, target_opset, targeted_onnx, custom_conversion_functions, custom_shape_calculators, without_onnx_ml, zipmap, split)\u001b[39m\n\u001b[32m     84\u001b[39m     name = \u001b[38;5;28mstr\u001b[39m(uuid4().hex)\n\u001b[32m     86\u001b[39m target_opset = target_opset \u001b[38;5;28;01mif\u001b[39;00m target_opset \u001b[38;5;28;01melse\u001b[39;00m get_maximum_opset_supported()\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m topology = \u001b[43mparse_lightgbm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_conversion_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_shape_calculators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m topology.compile()\n\u001b[32m     97\u001b[39m onnx_ml_model = convert_topology(\n\u001b[32m     98\u001b[39m     topology, name, doc_string, target_opset, targeted_onnx\n\u001b[32m     99\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fab47\\Documents\\dev\\predictempo\\.venv\\Lib\\site-packages\\onnxmltools\\convert\\lightgbm\\_parse.py:230\u001b[39m, in \u001b[36mparse_lightgbm\u001b[39m\u001b[34m(model, initial_types, target_opset, custom_conversion_functions, custom_shape_calculators, zipmap, split)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[32m    228\u001b[39m     raw_model_container.add_input(variable)\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m outputs = \u001b[43m_parse_lightgbm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[32m    233\u001b[39m     raw_model_container.add_output(variable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fab47\\Documents\\dev\\predictempo\\.venv\\Lib\\site-packages\\onnxmltools\\convert\\lightgbm\\_parse.py:197\u001b[39m, in \u001b[36m_parse_lightgbm\u001b[39m\u001b[34m(scope, model, inputs, zipmap, split)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03mThis is a delegate function. It doesn't nothing but\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03minvoke the correct parsing function according to the input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \u001b[33;03m:return: The output variables produced by the input model\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, LGBMClassifier):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_sklearn_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzipmap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, WrappedBooster) \u001b[38;5;129;01mand\u001b[39;00m model.operator_name == \u001b[33m\"\u001b[39m\u001b[33mLgbmClassifier\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_sklearn_classifier(scope, model, inputs, zipmap=zipmap)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fab47\\Documents\\dev\\predictempo\\.venv\\Lib\\site-packages\\onnxmltools\\convert\\lightgbm\\_parse.py:142\u001b[39m, in \u001b[36m_parse_sklearn_classifier\u001b[39m\u001b[34m(scope, model, inputs, zipmap)\u001b[39m\n\u001b[32m    139\u001b[39m this_operator.inputs = probability_tensor\n\u001b[32m    140\u001b[39m this_operator.zipmap = zipmap\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m classes = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\n\u001b[32m    143\u001b[39m label_type = Int64Type()\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model.classes_, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    146\u001b[39m     model.classes_[\u001b[32m0\u001b[39m], numpy.ndarray\n\u001b[32m    147\u001b[39m ):\n\u001b[32m    148\u001b[39m     \u001b[38;5;66;03m# multi-label problem\u001b[39;00m\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# this_operator.classlabels_int64s = list(range(0, len(classes)))\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fab47\\Documents\\dev\\predictempo\\.venv\\Lib\\site-packages\\lightgbm\\sklearn.py:1662\u001b[39m, in \u001b[36mLGBMClassifier.classes_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1660\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\":obj:`array` of shape = [n_classes]: The class label array.\"\"\"\u001b[39;00m\n\u001b[32m   1661\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__sklearn_is_fitted__():\n\u001b[32m-> \u001b[39m\u001b[32m1662\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LGBMNotFittedError(\u001b[33m\"\u001b[39m\u001b[33mNo classes found. Need to call fit beforehand.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1663\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._classes\n",
      "\u001b[31mNotFittedError\u001b[39m: No classes found. Need to call fit beforehand."
     ]
    }
   ],
   "source": [
    "from onnxmltools.convert import convert_lightgbm\n",
    "import onnx\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType\n",
    "\n",
    "# from onnxsim import simplify\n",
    "from onnx import helper\n",
    "\n",
    "X_train_np = X_train.to_numpy().astype(np.float32)\n",
    "initial_types = [(\"input\", FloatTensorType([None, X_train_np.shape[1]]))]\n",
    "input_names_str = \",\".join(X_train.columns)\n",
    "\n",
    "onnx_model = convert_lightgbm(\n",
    "    lgbm,\n",
    "    initial_types=initial_types,\n",
    "    target_opset=12,\n",
    "    zipmap=False,\n",
    "    doc_string=f\"Predict if the next day will be a red day.\\n\\nInput names: {input_names_str}\",\n",
    ")\n",
    "\n",
    "# Simplify the ONNX model to avoid unsupported operators in app later on\n",
    "# simp_model, check = simplify(onnx_model)\n",
    "# assert check, \"Simplified ONNX model could not be validated\"\n",
    "simp_model, check = onnx_model, True\n",
    "\n",
    "model = simp_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType\n",
    "\n",
    "# Convert base LGBM (raw scores)\n",
    "initial_types = [(\"input\", FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "lgbm_onnx = onnxmltools.convert_lightgbm(\n",
    "    cal.estimator,  # trained LGBM\n",
    "    initial_types=initial_types,\n",
    "    target_opset=12,\n",
    "    zipmap=False,\n",
    "    doc_string=f\"Predict if the next day will be a red day.\\n\\nInput names: {input_names_str}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import helper, TensorProto\n",
    "\n",
    "\n",
    "def get_platt_scaling_params(calibrated_lgbm) -> tuple[float, float]:\n",
    "    \"\"\"Get Platt scaling parameters 'a' and 'b' from a CalibratedClassifierCV.\"\"\"\n",
    "    cal = calibrated_lgbm.calibrated_classifiers_[0]\n",
    "    a = cal.calibrators[0].a_\n",
    "    b = cal.calibrators[0].b_\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def add_platt_scaling_to_onnx(\n",
    "    lgbm_onnx: onnx.ModelProto, calibrated_lgbm: CalibratedClassifierCV\n",
    ") -> onnx.ModelProto:\n",
    "    \"\"\"Add Platt scaling nodes to an existing LGBM ONNX model.\"\"\"\n",
    "\n",
    "    a, b = get_platt_scaling_params(calibrated_lgbm)\n",
    "\n",
    "    # Create constants for 'a' and 'b'\n",
    "    a_const = helper.make_tensor(\n",
    "        name=\"a\", data_type=TensorProto.FLOAT, dims=[], vals=[a]\n",
    "    )\n",
    "    b_const = helper.make_tensor(\n",
    "        name=\"b\", data_type=TensorProto.FLOAT, dims=[], vals=[b]\n",
    "    )\n",
    "\n",
    "    # Get existing ONNX graph\n",
    "    graph = lgbm_onnx.graph\n",
    "\n",
    "    # LGBM outputs both raw scores and probabilities at respectively output[0] and output[1]\n",
    "    # We'll output name index 1\n",
    "    output_index = 1\n",
    "    raw_output_name = graph.output[output_index].name\n",
    "    sigmoid_output_name = \"probability\"\n",
    "\n",
    "    # Multiply node: score * a\n",
    "    mul_node = helper.make_node(\n",
    "        \"Mul\", inputs=[raw_output_name, \"a\"], outputs=[\"scaled_score\"]\n",
    "    )\n",
    "\n",
    "    # Add node: scaled_score + b\n",
    "    add_node = helper.make_node(\n",
    "        \"Add\", inputs=[\"scaled_score\", \"b\"], outputs=[\"shifted_score\"]\n",
    "    )\n",
    "\n",
    "    # Sigmoid node\n",
    "    sigmoid_node = helper.make_node(\n",
    "        \"Sigmoid\", inputs=[\"shifted_score\"], outputs=[sigmoid_output_name]\n",
    "    )\n",
    "\n",
    "    # Add nodes to graph\n",
    "    graph.node.extend([mul_node, add_node, sigmoid_node])\n",
    "    graph.initializer.extend([a_const, b_const])\n",
    "\n",
    "    # Replace the old output with the new sigmoid output\n",
    "    graph.output[output_index].name = sigmoid_output_name\n",
    "\n",
    "\n",
    "add_platt_scaling_to_onnx(lgbm_onnx, calibrated_lgbm)\n",
    "model = lgbm_onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     93\u001b[39m     graph.output.clear()\n\u001b[32m     94\u001b[39m     graph.output.extend(new_outputs)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43madd_platt_scaling_to_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgbm_onnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalibrated_lgbm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m model = lgbm_onnx\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# ...existing code...\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36madd_platt_scaling_to_onnx\u001b[39m\u001b[34m(lgbm_onnx, calibrated_lgbm)\u001b[39m\n\u001b[32m      9\u001b[39m graph = lgbm_onnx.graph\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Get the 'scores' output (raw logits) from the original LGBM model (index 2)\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# This is typically a [N, 2] tensor where scores[:, 0] is for class 0 and scores[:, 1] for class 1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m raw_scores_output_name = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m.name\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Create constants for 'a' and 'b'\u001b[39;00m\n\u001b[32m     16\u001b[39m a_const = helper.make_tensor(\n\u001b[32m     17\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m, data_type=TensorProto.FLOAT, dims=[], vals=[a]\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "def add_platt_scaling_to_onnx(\n",
    "    lgbm_onnx: onnx.ModelProto, calibrated_lgbm: CalibratedClassifierCV\n",
    ") -> onnx.ModelProto:\n",
    "    \"\"\"Add Platt scaling nodes to an existing LGBM ONNX model.\"\"\"\n",
    "\n",
    "    a, b = get_platt_scaling_params(calibrated_lgbm)\n",
    "\n",
    "    graph = lgbm_onnx.graph\n",
    "\n",
    "    # Get the 'scores' output (raw logits) from the original LGBM model (index 2)\n",
    "    # This is typically a [N, 2] tensor where scores[:, 0] is for class 0 and scores[:, 1] for class 1\n",
    "    raw_scores_output_name = graph.output[2].name\n",
    "\n",
    "    # Create constants for 'a' and 'b'\n",
    "    a_const = helper.make_tensor(\n",
    "        name=\"a\", data_type=TensorProto.FLOAT, dims=[], vals=[a]\n",
    "    )\n",
    "    b_const = helper.make_tensor(\n",
    "        name=\"b\", data_type=TensorProto.FLOAT, dims=[], vals=[b]\n",
    "    )\n",
    "\n",
    "    # Extract the score for the positive class (assuming it's the second column, index 1)\n",
    "    # Use Gather to select the column for the positive class from the [N, 2] raw scores tensor\n",
    "    gather_index = helper.make_tensor(\n",
    "        name=\"gather_idx\", data_type=TensorProto.INT64, dims=[], vals=[1]\n",
    "    )\n",
    "    gather_node = helper.make_node(\n",
    "        \"Gather\",\n",
    "        inputs=[raw_scores_output_name, \"gather_idx\"],\n",
    "        outputs=[\"positive_class_raw_score\"],\n",
    "        axis=1  # Gather along the class dimension\n",
    "    )\n",
    "\n",
    "    # Multiply node: positive_class_raw_score * a\n",
    "    mul_node = helper.make_node(\n",
    "        \"Mul\", inputs=[\"positive_class_raw_score\", \"a\"], outputs=[\"scaled_score\"]\n",
    "    )\n",
    "\n",
    "    # Add node: scaled_score + b\n",
    "    add_node = helper.make_node(\n",
    "        \"Add\", inputs=[\"scaled_score\", \"b\"], outputs=[\"shifted_score\"]\n",
    "    )\n",
    "\n",
    "    # Sigmoid node to get P(class 1)\n",
    "    prob_pos_name = \"prob_positive_class\"\n",
    "    sigmoid_node = helper.make_node(\n",
    "        \"Sigmoid\", inputs=[\"shifted_score\"], outputs=[prob_pos_name]\n",
    "    )\n",
    "\n",
    "    # Compute P(class 0) = 1 - P(class 1)\n",
    "    one_const = helper.make_tensor(\n",
    "        name=\"one\", data_type=TensorProto.FLOAT, dims=[], vals=[1.0]\n",
    "    )\n",
    "    prob_neg_name = \"prob_negative_class\"\n",
    "    sub_node = helper.make_node(\n",
    "        \"Sub\", inputs=[\"one\", prob_pos_name], outputs=[prob_neg_name]\n",
    "    )\n",
    "\n",
    "    # Concatenate P(class 0) and P(class 1) into a [N, 2] tensor\n",
    "    calibrated_probabilities_name = \"probability\"  # This will be the new output name\n",
    "    concat_probs_node = helper.make_node(\n",
    "        \"Concat\",\n",
    "        inputs=[prob_neg_name, prob_pos_name],\n",
    "        outputs=[calibrated_probabilities_name],\n",
    "        axis=1,  # Concatenate along the class dimension\n",
    "    )\n",
    "\n",
    "    # Add new nodes and initializers to the graph\n",
    "    graph.node.extend(\n",
    "        [gather_node, mul_node, add_node, sigmoid_node, sub_node, concat_probs_node]\n",
    "    )\n",
    "    graph.initializer.extend([a_const, b_const, gather_index, one_const])\n",
    "\n",
    "    # Update the model's outputs list\n",
    "    # The new calibrated probabilities will replace the original 'probabilities' output (index 1)\n",
    "    # The 'label' output (index 0) and the original 'scores' output (index 2) might still exist.\n",
    "    \n",
    "    # Create a new list of outputs, replacing the old probabilities output with the new calibrated one\n",
    "    new_outputs = []\n",
    "    for i, output_tensor_info in enumerate(graph.output):\n",
    "        if i == 1: # This is the original 'probabilities' output\n",
    "            # Replace with the new calibrated probability output info\n",
    "            new_output_info = helper.make_tensor_value_info(\n",
    "                calibrated_probabilities_name, TensorProto.FLOAT, [None, 2] # Explicitly define shape\n",
    "            )\n",
    "            new_outputs.append(new_output_info)\n",
    "        elif i == 2: # This is the original 'scores' (raw logits) output, which is no longer a primary output\n",
    "            continue # Skip adding it to the new list\n",
    "        else: # Keep other outputs (like 'label' at index 0)\n",
    "            new_outputs.append(output_tensor_info)\n",
    "\n",
    "    graph.output.clear()\n",
    "    graph.output.extend(new_outputs)\n",
    "\n",
    "add_platt_scaling_to_onnx(lgbm_onnx, calibrated_lgbm)\n",
    "model = lgbm_onnx\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: [0, 21]\n",
      "Modified ONNX model saved as lgbm_model_red_days_2026_01_06.onnx\n"
     ]
    }
   ],
   "source": [
    "# Now we will modify the onnx model to name the input features\n",
    "graph = model.graph\n",
    "original_input = graph.input[0]  # Assuming there is only one input\n",
    "\n",
    "# Extract input name, type, and shape\n",
    "input_name = original_input.name\n",
    "input_type = original_input.type.tensor_type.elem_type  # Data type\n",
    "old_shape = original_input.type.tensor_type.shape.dim\n",
    "\n",
    "# Check current shape (should be [None, 20])\n",
    "print(\"Original Shape:\", [dim.dim_value for dim in old_shape])\n",
    "\n",
    "# Ensure features_names are unique for ONNX inputs\n",
    "# Convert to list to allow modification if needed\n",
    "features_names_list = X_train.columns.tolist()\n",
    "seen = set()\n",
    "unique_features_names = []\n",
    "for name in features_names_list:\n",
    "    original_name = name\n",
    "    counter = 1\n",
    "    # Append suffix if name is already seen\n",
    "    while name in seen:\n",
    "        name = f\"{original_name}_{counter}\"\n",
    "        counter += 1\n",
    "    seen.add(name)\n",
    "    unique_features_names.append(name)\n",
    "\n",
    "# Create separate input tensors (None, 1) using unique names\n",
    "new_inputs = [\n",
    "    helper.make_tensor_value_info(unique_features_names[i], input_type, [None, 1])\n",
    "    for i in range(len(unique_features_names))\n",
    "]\n",
    "\n",
    "# Create a new node that concatenates inputs (needed for LightGBM)\n",
    "concat_node = helper.make_node(\n",
    "    \"Concat\",\n",
    "    inputs=unique_features_names,  # Use the unique names for concatenation\n",
    "    outputs=[\"concatenated_input\"],\n",
    "    axis=1,  # feature axis\n",
    ")\n",
    "\n",
    "# Replace old input with new inputs and modify the first node to use `concatenated_input`\n",
    "graph.input.remove(original_input)\n",
    "graph.input.extend(new_inputs)\n",
    "\n",
    "# Find the first node that takes the original input and modify it\n",
    "for node in graph.node:\n",
    "    for i, input_name_in_node in enumerate(node.input):\n",
    "        if input_name_in_node == input_name:\n",
    "            node.input[i] = \"concatenated_input\"\n",
    "\n",
    "# Add the new Concat node at the beginning\n",
    "graph.node.insert(0, concat_node)\n",
    "\n",
    "# Save the modified model\n",
    "onnx_model_path = \"lgbm_model_red_days_2026_01_06.onnx\"\n",
    "onnx.save(model, onnx_model_path)\n",
    "\n",
    "print(f\"Modified ONNX model saved as {onnx_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Predictions should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[150]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m y_pred = calibrated_lgbm.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Compare the predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m np.allclose(\u001b[32m1\u001b[39m - y_pred, pred_onnx), \u001b[33m\"\u001b[39m\u001b[33mPredictions should be the same\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Predictions should be the same"
     ]
    }
   ],
   "source": [
    "# Load model to test it in python using onnxruntime:\n",
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(onnx_model_path)\n",
    "input_names = [i.name for i in sess.get_inputs()]\n",
    "label_name = sess.get_outputs()[1].name\n",
    "\n",
    "# Test the model\n",
    "X_test_np = X_test.to_numpy().astype(np.float32)\n",
    "input_data = {\n",
    "    input_name: np.expand_dims(X_test_np[..., i], axis=-1)\n",
    "    for i, input_name in enumerate(input_names)\n",
    "}\n",
    "pred_onnx = sess.run([label_name], input_data)[0][:, 1]\n",
    "\n",
    "y_pred = calibrated_lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compare the predictions\n",
    "assert np.allclose(1 - y_pred, pred_onnx), \"Predictions should be the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20472258, 0.9839077 ],\n",
       "       [0.19367915, 0.98496807],\n",
       "       [0.3743288 , 0.9633797 ],\n",
       "       [0.31628305, 0.97144794],\n",
       "       [0.21661091, 0.9827354 ],\n",
       "       [0.9264866 , 0.55532795],\n",
       "       [0.3143667 , 0.97169316],\n",
       "       [0.25991333, 0.97817373],\n",
       "       [0.8057909 , 0.79138005],\n",
       "       [0.58903635, 0.9165348 ],\n",
       "       [0.20089364, 0.9842784 ],\n",
       "       [0.19967353, 0.98439574],\n",
       "       [0.6528626 , 0.8932624 ],\n",
       "       [0.36418235, 0.96488607],\n",
       "       [0.31546605, 0.9715526 ],\n",
       "       [0.2002849 , 0.98433703],\n",
       "       [0.21371666, 0.98302376],\n",
       "       [0.23757464, 0.98058635],\n",
       "       [0.32763398, 0.96996975],\n",
       "       [0.22710988, 0.9816725 ],\n",
       "       [0.26464838, 0.97764504],\n",
       "       [0.34724212, 0.9673065 ],\n",
       "       [0.27716213, 0.9762175 ],\n",
       "       [0.19957006, 0.98440576],\n",
       "       [0.19552666, 0.98479253],\n",
       "       [0.20542544, 0.9838392 ],\n",
       "       [0.2040357 , 0.9839744 ],\n",
       "       [0.6550251 , 0.89234793],\n",
       "       [0.3626784 , 0.96510553],\n",
       "       [0.19957006, 0.98440576],\n",
       "       [0.37418383, 0.96340144],\n",
       "       [0.24104047, 0.9802206 ],\n",
       "       [0.2923153 , 0.9744272 ],\n",
       "       [0.22704339, 0.9816793 ],\n",
       "       [0.9556054 , 0.4223648 ],\n",
       "       [0.66170365, 0.889462  ],\n",
       "       [0.9556923 , 0.4218644 ],\n",
       "       [0.26689535, 0.977392  ],\n",
       "       [0.28600252, 0.9751814 ],\n",
       "       [0.6050543 , 0.91129756],\n",
       "       [0.20917341, 0.9834726 ],\n",
       "       [0.2174395 , 0.9826524 ],\n",
       "       [0.51160294, 0.9375985 ],\n",
       "       [0.5032491 , 0.93952566],\n",
       "       [0.22229165, 0.98216355],\n",
       "       [0.27494177, 0.9764741 ],\n",
       "       [0.35731608, 0.965881  ],\n",
       "       [0.42566478, 0.9550286 ],\n",
       "       [0.2769413 , 0.976243  ],\n",
       "       [0.22938526, 0.9814387 ],\n",
       "       [0.21751827, 0.98264456],\n",
       "       [0.21770504, 0.98262584],\n",
       "       [0.20782915, 0.98360443],\n",
       "       [0.8144752 , 0.78190416],\n",
       "       [0.24109238, 0.9802151 ],\n",
       "       [0.33167085, 0.96943307],\n",
       "       [0.3553216 , 0.9661664 ],\n",
       "       [0.55295086, 0.92713916],\n",
       "       [0.3655478 , 0.9646858 ],\n",
       "       [0.19618407, 0.9847299 ],\n",
       "       [0.22880653, 0.98149824],\n",
       "       [0.20851335, 0.9835373 ],\n",
       "       [0.1940814 , 0.9849299 ],\n",
       "       [0.20722029, 0.98366404],\n",
       "       [0.29142177, 0.97453463],\n",
       "       [0.36938375, 0.9641193 ],\n",
       "       [0.97381866, 0.29733396],\n",
       "       [0.19957006, 0.98440576],\n",
       "       [0.22843221, 0.98153675],\n",
       "       [0.25655323, 0.97854507],\n",
       "       [0.2346943 , 0.980888  ],\n",
       "       [0.29419044, 0.9742007 ],\n",
       "       [0.6498934 , 0.8945027 ],\n",
       "       [0.19629937, 0.9847189 ],\n",
       "       [0.43691576, 0.9530168 ],\n",
       "       [0.20331332, 0.9840445 ],\n",
       "       [0.7152727 , 0.8623588 ],\n",
       "       [0.42825827, 0.9545711 ],\n",
       "       [0.2101214 , 0.98337936],\n",
       "       [0.6922039 , 0.87497807],\n",
       "       [0.96316075, 0.37577918],\n",
       "       [0.2168318 , 0.9827133 ],\n",
       "       [0.2169145 , 0.982705  ],\n",
       "       [0.8903563 , 0.65965724],\n",
       "       [0.97298396, 0.30411434],\n",
       "       [0.2963737 , 0.9739357 ],\n",
       "       [0.30669636, 0.9726621 ],\n",
       "       [0.71378267, 0.86322355],\n",
       "       [0.27510166, 0.9764557 ],\n",
       "       [0.33887726, 0.9684601 ],\n",
       "       [0.22807482, 0.9815735 ],\n",
       "       [0.7117562 , 0.864388  ],\n",
       "       [0.19957006, 0.98440576],\n",
       "       [0.2969858 , 0.9738612 ],\n",
       "       [0.26674968, 0.97740847],\n",
       "       [0.20389897, 0.9839877 ],\n",
       "       [0.3572368 , 0.9658923 ],\n",
       "       [0.2711801 , 0.97690547],\n",
       "       [0.97649634, 0.27474868],\n",
       "       [0.21402523, 0.9829931 ],\n",
       "       [0.19367915, 0.98496807],\n",
       "       [0.91686356, 0.5879938 ],\n",
       "       [0.38732523, 0.9613846 ],\n",
       "       [0.89651275, 0.64499   ],\n",
       "       [0.25397825, 0.97882766],\n",
       "       [0.23037201, 0.9813369 ],\n",
       "       [0.6961373 , 0.8729372 ],\n",
       "       [0.5459054 , 0.9290385 ],\n",
       "       [0.9747828 , 0.2893514 ],\n",
       "       [0.7043519 , 0.8685324 ],\n",
       "       [0.4083377 , 0.9579926 ],\n",
       "       [0.5271697 , 0.9338485 ],\n",
       "       [0.9431344 , 0.48691142],\n",
       "       [0.2821995 , 0.97563004],\n",
       "       [0.20893082, 0.9834964 ],\n",
       "       [0.23431906, 0.9809272 ],\n",
       "       [0.25824106, 0.9783589 ],\n",
       "       [0.9032416 , 0.62770426],\n",
       "       [0.9505465 , 0.45020264],\n",
       "       [0.22487366, 0.9819011 ],\n",
       "       [0.4172847 , 0.9564819 ],\n",
       "       [0.25271693, 0.9789654 ],\n",
       "       [0.8444346 , 0.7435594 ],\n",
       "       [0.19367915, 0.98496807],\n",
       "       [0.5616597 , 0.9247184 ],\n",
       "       [0.19786188, 0.98456955],\n",
       "       [0.23310316, 0.9810538 ],\n",
       "       [0.2121276 , 0.98318124],\n",
       "       [0.81564474, 0.7805782 ],\n",
       "       [0.5588423 , 0.9255105 ],\n",
       "       [0.2381354 , 0.9805274 ],\n",
       "       [0.4163645 , 0.9566392 ],\n",
       "       [0.97825223, 0.25920546],\n",
       "       [0.44938144, 0.9507023 ],\n",
       "       [0.62551045, 0.904058  ],\n",
       "       [0.21205926, 0.98318803],\n",
       "       [0.66869795, 0.88633615],\n",
       "       [0.40567958, 0.9584336 ],\n",
       "       [0.9757262 , 0.28137922],\n",
       "       [0.9384373 , 0.5079978 ],\n",
       "       [0.8508425 , 0.73398364],\n",
       "       [0.23964012, 0.98036873],\n",
       "       [0.4177517 , 0.9564018 ],\n",
       "       [0.48718423, 0.9430759 ],\n",
       "       [0.24104047, 0.9802206 ],\n",
       "       [0.97967803, 0.24612877],\n",
       "       [0.4987476 , 0.94054073],\n",
       "       [0.21494406, 0.9829017 ],\n",
       "       [0.33191538, 0.9694003 ],\n",
       "       [0.38408837, 0.9618886 ],\n",
       "       [0.2722826 , 0.9767795 ],\n",
       "       [0.19967353, 0.98439574],\n",
       "       [0.27972126, 0.97591996],\n",
       "       [0.957398  , 0.41188848],\n",
       "       [0.29025903, 0.9746742 ],\n",
       "       [0.23498714, 0.9808575 ],\n",
       "       [0.2140075 , 0.9829948 ],\n",
       "       [0.26149988, 0.9779973 ],\n",
       "       [0.9313983 , 0.5368787 ],\n",
       "       [0.877053  , 0.6881188 ],\n",
       "       [0.19763684, 0.9845911 ],\n",
       "       [0.7774606 , 0.8183524 ],\n",
       "       [0.95359707, 0.43371174],\n",
       "       [0.21855217, 0.98254085],\n",
       "       [0.892261  , 0.65522915],\n",
       "       [0.19367915, 0.98496807],\n",
       "       [0.86751187, 0.70620376],\n",
       "       [0.8646275 , 0.7113366 ],\n",
       "       [0.23875788, 0.98046184],\n",
       "       [0.71464396, 0.8627246 ],\n",
       "       [0.97192895, 0.31251457],\n",
       "       [0.5082434 , 0.9383805 ],\n",
       "       [0.2113958 , 0.9832536 ],\n",
       "       [0.6381974 , 0.8992214 ],\n",
       "       [0.2880004 , 0.97494406],\n",
       "       [0.7878106 , 0.8091312 ],\n",
       "       [0.8239919 , 0.77074504],\n",
       "       [0.23529384, 0.9808254 ],\n",
       "       [0.23013514, 0.9813614 ],\n",
       "       [0.23431906, 0.9809272 ],\n",
       "       [0.9756793 , 0.28177932],\n",
       "       [0.20328876, 0.9840468 ],\n",
       "       [0.22738606, 0.9816442 ],\n",
       "       [0.9741612 , 0.29451668],\n",
       "       [0.6769596 , 0.8824998 ],\n",
       "       [0.7685722 , 0.82576233],\n",
       "       [0.96407986, 0.3696496 ],\n",
       "       [0.979286  , 0.24976566],\n",
       "       [0.20491561, 0.98388886],\n",
       "       [0.3812917 , 0.9623202 ],\n",
       "       [0.28850722, 0.9748837 ],\n",
       "       [0.3328011 , 0.9692817 ],\n",
       "       [0.19456843, 0.98488367],\n",
       "       [0.2587186 , 0.9783061 ],\n",
       "       [0.91635484, 0.58960503],\n",
       "       [0.19552666, 0.98479253],\n",
       "       [0.9676739 , 0.34459865],\n",
       "       [0.25267243, 0.9789703 ],\n",
       "       [0.78645456, 0.81037796],\n",
       "       [0.8888991 , 0.6629814 ],\n",
       "       [0.23107961, 0.98126364],\n",
       "       [0.2232799 , 0.9820633 ],\n",
       "       [0.97388244, 0.29681128],\n",
       "       [0.33480805, 0.96901184],\n",
       "       [0.95400727, 0.4314264 ],\n",
       "       [0.2466372 , 0.9796234 ],\n",
       "       [0.78931355, 0.8077352 ],\n",
       "       [0.97803086, 0.2611987 ]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([label_name], input_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.9839077 , 0.98496807, 0.9633797 , 0.97144794, 0.9827354 ,\n",
       "        0.55532795, 0.97169316, 0.97817373, 0.79138005, 0.9165348 ],\n",
       "       dtype=float32),\n",
       " array([0.01531868, 0.01559424, 0.02791771, 0.02855204, 0.01588213,\n",
       "        0.43792225, 0.11243358, 0.01969074, 0.19371337, 0.42989881]))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onnx[0:10],  y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.18863028"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.20472258 + 0.9839077 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictempo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
